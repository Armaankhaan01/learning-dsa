# ğŸ“š Learning DSA â€” My Notes & Explanations

Welcome to my **Data Structures and Algorithms (DSA)** learning repository!  
This repo is my personal space to take structured notes, write explanations, and document problem-solving patterns â€” all in clean Markdown format.  

Iâ€™m learning concepts one topic at a time and writing them here for quick revision and long-term reference.  
Each section will include:
- ğŸ“˜ Core concept explanation  
- ğŸ’¡ Example code (in Python/JavaScript)  
- â±ï¸ Time and Space Complexity  
- ğŸ§© Common patterns and interview notes  

---

## ğŸ¯ Learning Resources

Iâ€™m following and learning DSA from the following sources:

- ğŸŒ **[algomap.io](https://algomap.io)** â€” interactive DSA roadmap and concept visualizer  
- â–¶ï¸ **[YouTube Playlist](https://www.youtube.com/playlist?list=PLKYEe2WisBTFEr6laH5bR2J19j7sl5O8R)** â€” structured DSA video series  
- ğŸ“ Notes are written and organized **according to the above roadmap and playlist flow**


> âš™ï¸ Repository Goal: Build a clear, well-organized set of DSA notes that grow as I progress â€” from basics to advanced topics like graphs, recursion, and dynamic programming.

---

_ğŸ§  Formatting, structure, and Markdown layout styled with help from **ChatGPT (GPT-5)** for readability and consistency._

---

# ğŸ§  Notes on **Time & Space Complexity + Big O Notation**

---

## ğŸ“ 1. What is Time Complexity?

**Time Complexity** measures how the *execution time* of an algorithm grows with the size of the input `n`.

Itâ€™s not measured in seconds â€” itâ€™s measured in **number of operations**.

---

### Example 1 â€“ Square all numbers in an array

```python
def square(arr):
    result = []
    for num in arr:
        result.append(num ** 2)
    return result
```

* The loop runs once for each element.
* For an array of `n` elements â†’ we do `n` operations.

âœ… **Time Complexity:** `O(n)` â†’ *Linear time*
ğŸ“ˆ As `n` doubles, time doubles.

---

### Example 2 â€“ Find all pairs of numbers

You generate every pair `(a, b)` in the array.

```python
def all_pairs(arr):
    pairs = []
    for i in range(len(arr)):
        for j in range(i + 1, len(arr)):
            pairs.append((arr[i], arr[j]))
    return pairs
```

* Outer loop runs `n` times
* Inner loop runs up to `n` times for each outer iteration

âœ… **Time Complexity:** `O(nÂ²)` â†’ *Quadratic time*
ğŸ“ˆ As `n` doubles, time increases 4Ã—.

---

## ğŸ§¾ 2. Visualizing Time Complexities

| Type         | Big O        | Shape on Graph             | Example                     |
| ------------ | ------------ | -------------------------- | --------------------------- |
| Constant     | `O(1)`       | Horizontal line            | Access first element        |
| Linear       | `O(n)`       | Straight diagonal line     | Loop through array          |
| Quadratic    | `O(nÂ²)`      | Steep parabola             | Nested loops                |
| Cubic        | `O(nÂ³)`      | Even steeper curve         | 3 nested loops              |
| Logarithmic  | `O(log n)`   | Slowly rising curve        | Binary search               |
| Linearithmic | `O(n log n)` | Between linear & quadratic | Merge sort, quick sort      |
| Exponential  | `O(2â¿)`      | Explosive growth           | Recursive subset generation |
| Factorial    | `O(n!)`      | Impossible for large n     | Permutations                |

---

## ğŸ§© 3. Understanding Big O

**Big O Notation** describes the *upper bound* â€” the *worst-case* growth rate of an algorithm.

It basically asks:

> â€œCan I draw a function thatâ€™s always equal to or **worse** (grows faster) than my algorithm?â€

---

### Example:

If algorithm A takes `n` operations
â†’ itâ€™s `O(n)`

If algorithm B takes `nÂ²` operations
â†’ itâ€™s `O(nÂ²)`
and itâ€™s **not** `O(n)` because no straight line can bound a parabola from above.

---

## ğŸ§® 4. Simplifying Big O Expressions

We drop:

* **Constants** â†’ because they donâ€™t affect growth rate
* **Lower-order terms** â†’ because theyâ€™re negligible as `n` grows

---

### Example:

```
O(nÂ² + 2n + 1) â†’ O(nÂ²)
O(5nÂ²) â†’ O(nÂ²)
O(3nÂ³ + 5nÂ²) â†’ O(nÂ³)
```

Why?

> As `n â†’ âˆ`, the *highest power of n* dominates.

---

## ğŸ’¾ 5. Space Complexity

**Space Complexity** measures how much *extra memory* your algorithm needs.

---

### Example 1 â€“ Creating a new array

```python
def square(arr):
    result = []
    for num in arr:
        result.append(num ** 2)
    return result
```

* Uses extra space proportional to size of input â†’ `O(n)`

---

### Example 2 â€“ Modifying the array in-place

```python
def square_in_place(arr):
    for i in range(len(arr)):
        arr[i] = arr[i] ** 2
    return arr
```

* Doesnâ€™t create a new array
  âœ… **Space Complexity:** `O(1)` â†’ *Constant space*

---

## âš¡ 6. Constant Time Operations (`O(1)`)

Operations that take the same amount of time **no matter the input size**.

Examples:

* Accessing `arr[0]`
* Returning first element
* Printing a fixed number
* Simple arithmetic operations
* Hash lookups (average case)

---

### Note:

`O(1)` â‰  â€œone operationâ€
â†’ it just means **constant number of operations** (like 3, 5, etc.), not dependent on `n`.

Example:

```python
a[0], a[1], a[2]  # still O(1)
```

---

## ğŸ“‰ 7. Typical Growth Rates (From Best to Worst)

| Complexity   | Name         | Common Example          |
| ------------ | ------------ | ----------------------- |
| `O(1)`       | Constant     | Accessing array index   |
| `O(log n)`   | Logarithmic  | Binary search           |
| `O(n)`       | Linear       | Single loop             |
| `O(n log n)` | Linearithmic | Merge sort, quick sort  |
| `O(nÂ²)`      | Quadratic    | Nested loops            |
| `O(nÂ³)`      | Cubic        | 3 nested loops          |
| `O(2â¿)`      | Exponential  | Recursion on subsets    |
| `O(n!)`      | Factorial    | Permutations generation |

---

## âš™ï¸ 8. Big O Laws (Quick Rules)

1. **Drop constants:**
   `O(2n)` â†’ `O(n)`

2. **Drop smaller terms:**
   `O(nÂ² + n)` â†’ `O(nÂ²)`

3. **Multiplying loops:**

   ```
   for i in range(n):
       for j in range(n):
           ...
   ```

   â†’ `O(nÂ²)`

4. **Sequential loops:**

   ```
   for i in range(n):
       ...
   for j in range(n):
       ...
   ```

   â†’ `O(n) + O(n)` = `O(n)`

---

## ğŸ§± 9. Quick Summary of Examples

| Operation            | Time Complexity | Space Complexity |
| -------------------- | --------------- | ---------------- |
| Access array element | O(1)            | O(1)             |
| Loop through array   | O(n)            | O(1)             |
| Nested loop (pairs)  | O(nÂ²)           | O(nÂ²)            |
| Create new array     | O(n)            | O(n)             |
| Modify in place      | O(n)            | O(1)             |
| Binary search        | O(log n)        | O(1)             |
| Merge sort           | O(n log n)      | O(n)             |

---

## ğŸ§  10. Final Takeaways

* **Time Complexity** â†’ how long your code runs
* **Space Complexity** â†’ how much memory it uses
* **Big O Notation** â†’ upper bound on growth
* **Ignore constants and lower-order terms**
* **Aim for**:

  * O(1) â†’ Best
  * O(log n) â†’ Great
  * O(n) â†’ Good
  * Avoid O(nÂ²)+ unless absolutely necessary

---
